import json
from prompts import system_prompt
from prompts import summary_prompt
from llm import call_model
from db_connection import create_query


def question(question):
    llm_query = call_model(system_prompt, user_prompt=question)
    json_query = json.loads(llm_query)
    print(json_query) # cypher generated by the LLM
    if json_query["query"] == "None":
        return "No database query"
    db_response = create_query(json_query['query'])
    print(db_response) # Info returned from the db using the cypher query above
    user_prompt= llm_query + " response: " + str(db_response)
    return call_model(summary_prompt, user_prompt)


print(question("What did I spend more on Sainsburys or Tesco?"))
